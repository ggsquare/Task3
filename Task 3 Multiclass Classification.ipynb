{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tables import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([45324, 45325, 45326, 45327, 45328, 45329, 45330, 45331, 45332,\n",
       "            45333,\n",
       "            ...\n",
       "            53451, 53452, 53453, 53454, 53455, 53456, 53457, 53458, 53459,\n",
       "            53460],\n",
       "           dtype='int64', length=8137)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_hdf(\"train.h5\", \"train\")\n",
    "test = pd.read_hdf(\"test.h5\", \"test\")\n",
    "\n",
    "#View training data\n",
    "#train.shape (45324, 101)\n",
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['y']\n",
    "x_train = train._drop_axis(['y'], axis=1)\n",
    "\n",
    "#Switch to numpy\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert y to 1-hot for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 classes: 0,1,2,3,4\n",
    "y_train_hot = np.zeros((y_train.shape[0], 5))\n",
    "y_train_hot[np.arange(y_train.shape[0]), y_train] = 1\n",
    "\n",
    "#see 1-hot\n",
    "#y_train_hot[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "disp_step = 2\n",
    "logs_path = './tmp/tensorflow_logs' #for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders, fed by training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('DATA'):\n",
    "    X = tf.placeholder(tf.float32, [None, 100], name='X')\n",
    "    y = tf.placeholder(tf.float32, [None, 5], name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables, to be learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('VARIABLES'):\n",
    "    W = tf.Variable(tf.zeros([100, 5]), name='weights')\n",
    "    b = tf.Variable(tf.zeros([5]), name='biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('SOFTMAX'): \n",
    "    pred = tf.nn.softmax(tf.matmul(X, W) + b, name='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss function: Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('LOSS'):\n",
    "    loss = tf.losses.softmax_cross_entropy(y, tf.log(pred))\n",
    "    tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('OPTIMIZER'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and run session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0002 loss= 0.012311707\n",
      "Epoch:  0004 loss= 0.025605847\n",
      "Epoch:  0006 loss= 0.071245542\n",
      "Epoch:  0008 loss= 0.054519955\n",
      "Epoch:  0010 loss= 0.084187069\n",
      "Epoch:  0012 loss= 0.044476904\n",
      "Epoch:  0014 loss= 0.087728533\n",
      "Epoch:  0016 loss= 0.055237377\n",
      "Epoch:  0018 loss= 0.029304576\n",
      "Epoch:  0020 loss= 0.035769186\n",
      "Optimization finished.\n",
      "Accuracy:  0.3850278\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "    merged_summaries = tf.summary.merge_all()\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    #Train the model\n",
    "    \n",
    "    #Run number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = 0\n",
    "        total_batch = int(x_train.shape[0]/batch_size)\n",
    "        \n",
    "        #Loop over the batchs for each epoch\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = x_train[(i*batch_size):(i+batch_size)+batch_size-1]\n",
    "            batch_ys = y_train_hot[(i*batch_size):(i+batch_size)+batch_size-1]\n",
    "            \n",
    "            _, c = sess.run([optimizer, loss], feed_dict={X: batch_xs, y: batch_ys})\n",
    "            \n",
    "            if i % 25 == 0:\n",
    "                s = sess.run(merged_summaries, feed_dict={X: batch_xs, y: batch_ys})\n",
    "                writer.add_summary(s, epoch*total_batch + i)\n",
    "                \n",
    "            avg_loss += c / total_batch\n",
    "            \n",
    "        if(epoch+1) % disp_step == 0:\n",
    "            print(\"Epoch: \", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(avg_loss))\n",
    "            \n",
    "    print('Optimization finished.')\n",
    "    \n",
    "    ### EVALUTATE\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict={X: x_train, y: y_train_hot}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aaa28c6b1225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_hot\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', sess.run(accuracy, feed_dict={X: x_train, y: y_train_hot}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS ATTEMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "num_examples = x_train.shape[0]\n",
    "\n",
    "#Define model\n",
    "model = Sequential([Dense(70, input_shape=(100,)), #a bit counterintuitve\n",
    "                   Activation('relu'),\n",
    "                   Dense(30),\n",
    "                   Activation('relu'),\n",
    "                   Dense(50),\n",
    "                   Activation('relu'),\n",
    "                   Dense(20),\n",
    "                   Activation('relu'),\n",
    "                   Dense(5),\n",
    "                   Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "45324/45324 [==============================] - 2s 43us/step - loss: 1.1017 - acc: 0.5377\n",
      "Epoch 2/400\n",
      "45324/45324 [==============================] - 2s 47us/step - loss: 0.8424 - acc: 0.6683\n",
      "Epoch 3/400\n",
      "45324/45324 [==============================] - 2s 45us/step - loss: 0.7395 - acc: 0.7144: 0s - loss: 0.7400 - acc\n",
      "Epoch 4/400\n",
      "45324/45324 [==============================] - 2s 47us/step - loss: 0.6912 - acc: 0.7362\n",
      "Epoch 5/400\n",
      "45324/45324 [==============================] - 2s 47us/step - loss: 0.6561 - acc: 0.7510\n",
      "Epoch 6/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.6203 - acc: 0.7643\n",
      "Epoch 7/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.5918 - acc: 0.7778\n",
      "Epoch 8/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.5714 - acc: 0.7861\n",
      "Epoch 9/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.5449 - acc: 0.7951\n",
      "Epoch 10/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.5321 - acc: 0.8013\n",
      "Epoch 11/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.5177 - acc: 0.8054\n",
      "Epoch 12/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.5108 - acc: 0.8107\n",
      "Epoch 13/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.4936 - acc: 0.8158\n",
      "Epoch 14/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.4902 - acc: 0.8165\n",
      "Epoch 15/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.4682 - acc: 0.8276\n",
      "Epoch 16/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.4642 - acc: 0.8273\n",
      "Epoch 17/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.4579 - acc: 0.8297\n",
      "Epoch 18/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.4502 - acc: 0.8322\n",
      "Epoch 19/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.4414 - acc: 0.8368\n",
      "Epoch 20/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.4375 - acc: 0.8382\n",
      "Epoch 21/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.4281 - acc: 0.8435\n",
      "Epoch 22/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.4266 - acc: 0.8403\n",
      "Epoch 23/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.4221 - acc: 0.8436\n",
      "Epoch 24/400\n",
      "45324/45324 [==============================] - 2s 48us/step - loss: 0.4151 - acc: 0.8460\n",
      "Epoch 25/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.4112 - acc: 0.8493\n",
      "Epoch 26/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.4086 - acc: 0.8505\n",
      "Epoch 27/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.4078 - acc: 0.8502\n",
      "Epoch 28/400\n",
      "45324/45324 [==============================] - 3s 64us/step - loss: 0.4073 - acc: 0.8489\n",
      "Epoch 29/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.3984 - acc: 0.8550\n",
      "Epoch 30/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3925 - acc: 0.8566\n",
      "Epoch 31/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.3941 - acc: 0.8540\n",
      "Epoch 32/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3895 - acc: 0.8574\n",
      "Epoch 33/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.3866 - acc: 0.8558\n",
      "Epoch 34/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.3814 - acc: 0.8588\n",
      "Epoch 35/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3768 - acc: 0.8612\n",
      "Epoch 36/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3790 - acc: 0.8613\n",
      "Epoch 37/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3728 - acc: 0.8641\n",
      "Epoch 38/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3669 - acc: 0.8658\n",
      "Epoch 39/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3678 - acc: 0.8665\n",
      "Epoch 40/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3657 - acc: 0.8652\n",
      "Epoch 41/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.3616 - acc: 0.8681\n",
      "Epoch 42/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3609 - acc: 0.8687\n",
      "Epoch 43/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3563 - acc: 0.8690\n",
      "Epoch 44/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3612 - acc: 0.8694\n",
      "Epoch 45/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3546 - acc: 0.8701\n",
      "Epoch 46/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3553 - acc: 0.8704\n",
      "Epoch 47/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3503 - acc: 0.8729\n",
      "Epoch 48/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3507 - acc: 0.8727\n",
      "Epoch 49/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3468 - acc: 0.8746\n",
      "Epoch 50/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3476 - acc: 0.8734\n",
      "Epoch 51/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.3407 - acc: 0.8752\n",
      "Epoch 52/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3435 - acc: 0.8754\n",
      "Epoch 53/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3387 - acc: 0.8762\n",
      "Epoch 54/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.3390 - acc: 0.8770\n",
      "Epoch 55/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.3404 - acc: 0.8762\n",
      "Epoch 56/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3349 - acc: 0.8793\n",
      "Epoch 57/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3297 - acc: 0.8815\n",
      "Epoch 58/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.3340 - acc: 0.8768\n",
      "Epoch 59/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.3275 - acc: 0.8813\n",
      "Epoch 60/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.3290 - acc: 0.8803\n",
      "Epoch 61/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.3281 - acc: 0.8808\n",
      "Epoch 62/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.3246 - acc: 0.8827\n",
      "Epoch 63/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.3246 - acc: 0.8837\n",
      "Epoch 64/400\n",
      "45324/45324 [==============================] - 3s 62us/step - loss: 0.3226 - acc: 0.8820\n",
      "Epoch 65/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.3234 - acc: 0.8830\n",
      "Epoch 66/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.3241 - acc: 0.8807\n",
      "Epoch 67/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.3189 - acc: 0.8845\n",
      "Epoch 68/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.3182 - acc: 0.8847\n",
      "Epoch 69/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.3174 - acc: 0.8858\n",
      "Epoch 70/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.3163 - acc: 0.8860\n",
      "Epoch 71/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.3174 - acc: 0.8849\n",
      "Epoch 72/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3127 - acc: 0.8868\n",
      "Epoch 73/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3152 - acc: 0.8857\n",
      "Epoch 74/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.3149 - acc: 0.8863\n",
      "Epoch 75/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.3121 - acc: 0.8861\n",
      "Epoch 76/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.3091 - acc: 0.8879\n",
      "Epoch 77/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.3089 - acc: 0.8877\n",
      "Epoch 78/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.3083 - acc: 0.8894\n",
      "Epoch 79/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.3064 - acc: 0.8876\n",
      "Epoch 80/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.3027 - acc: 0.8910\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.3037 - acc: 0.8910\n",
      "Epoch 82/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3028 - acc: 0.8903\n",
      "Epoch 83/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3020 - acc: 0.8910\n",
      "Epoch 84/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.3010 - acc: 0.8897\n",
      "Epoch 85/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.3027 - acc: 0.8907\n",
      "Epoch 86/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2962 - acc: 0.8930\n",
      "Epoch 87/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.3003 - acc: 0.8919\n",
      "Epoch 88/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2961 - acc: 0.8928\n",
      "Epoch 89/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2979 - acc: 0.8919\n",
      "Epoch 90/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2978 - acc: 0.8912\n",
      "Epoch 91/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2946 - acc: 0.8922\n",
      "Epoch 92/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2878 - acc: 0.8956\n",
      "Epoch 93/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2960 - acc: 0.8910\n",
      "Epoch 94/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2934 - acc: 0.8933\n",
      "Epoch 95/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2914 - acc: 0.8953\n",
      "Epoch 96/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2890 - acc: 0.8955\n",
      "Epoch 97/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2893 - acc: 0.8959\n",
      "Epoch 98/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2861 - acc: 0.8967\n",
      "Epoch 99/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2906 - acc: 0.8944\n",
      "Epoch 100/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2874 - acc: 0.8948\n",
      "Epoch 101/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2880 - acc: 0.8954\n",
      "Epoch 102/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2877 - acc: 0.8971\n",
      "Epoch 103/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2867 - acc: 0.8962\n",
      "Epoch 104/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2860 - acc: 0.8970\n",
      "Epoch 105/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2855 - acc: 0.8946\n",
      "Epoch 106/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2847 - acc: 0.8952\n",
      "Epoch 107/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2807 - acc: 0.8987\n",
      "Epoch 108/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2837 - acc: 0.8988\n",
      "Epoch 109/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2833 - acc: 0.8967\n",
      "Epoch 110/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2799 - acc: 0.8992\n",
      "Epoch 111/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2815 - acc: 0.8984\n",
      "Epoch 112/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2790 - acc: 0.8985\n",
      "Epoch 113/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2792 - acc: 0.8984\n",
      "Epoch 114/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2780 - acc: 0.8995\n",
      "Epoch 115/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2824 - acc: 0.8986\n",
      "Epoch 116/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2790 - acc: 0.8993\n",
      "Epoch 117/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2787 - acc: 0.8984\n",
      "Epoch 118/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2801 - acc: 0.8987\n",
      "Epoch 119/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2742 - acc: 0.9005\n",
      "Epoch 120/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2737 - acc: 0.9008\n",
      "Epoch 121/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2738 - acc: 0.9012\n",
      "Epoch 122/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2730 - acc: 0.9016\n",
      "Epoch 123/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2746 - acc: 0.9001\n",
      "Epoch 124/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2697 - acc: 0.9035\n",
      "Epoch 125/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2725 - acc: 0.8998\n",
      "Epoch 126/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2725 - acc: 0.9014\n",
      "Epoch 127/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2720 - acc: 0.8998\n",
      "Epoch 128/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2702 - acc: 0.9006\n",
      "Epoch 129/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2710 - acc: 0.9016\n",
      "Epoch 130/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2717 - acc: 0.9019\n",
      "Epoch 131/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2692 - acc: 0.9020\n",
      "Epoch 132/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2652 - acc: 0.9035\n",
      "Epoch 133/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2680 - acc: 0.9033\n",
      "Epoch 134/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2720 - acc: 0.9009\n",
      "Epoch 135/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2665 - acc: 0.9037\n",
      "Epoch 136/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2683 - acc: 0.9018\n",
      "Epoch 137/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2697 - acc: 0.9006\n",
      "Epoch 138/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2668 - acc: 0.9027\n",
      "Epoch 139/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2656 - acc: 0.9044\n",
      "Epoch 140/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2658 - acc: 0.9039\n",
      "Epoch 141/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2634 - acc: 0.9048: 0s - loss: 0.2641 - acc: 0.9\n",
      "Epoch 142/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2667 - acc: 0.9039\n",
      "Epoch 143/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2638 - acc: 0.9033\n",
      "Epoch 144/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2660 - acc: 0.9029\n",
      "Epoch 145/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2666 - acc: 0.9031\n",
      "Epoch 146/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2623 - acc: 0.9053\n",
      "Epoch 147/400\n",
      "45324/45324 [==============================] - 2s 48us/step - loss: 0.2614 - acc: 0.9045\n",
      "Epoch 148/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2625 - acc: 0.9048\n",
      "Epoch 149/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2633 - acc: 0.9055\n",
      "Epoch 150/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2637 - acc: 0.9051\n",
      "Epoch 151/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2600 - acc: 0.9057\n",
      "Epoch 152/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2605 - acc: 0.9045\n",
      "Epoch 153/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2583 - acc: 0.9066\n",
      "Epoch 154/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2607 - acc: 0.9067\n",
      "Epoch 155/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.2610 - acc: 0.9053\n",
      "Epoch 156/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2576 - acc: 0.9072\n",
      "Epoch 157/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2597 - acc: 0.9062\n",
      "Epoch 158/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2565 - acc: 0.9066\n",
      "Epoch 159/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2569 - acc: 0.9078\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2588 - acc: 0.9063\n",
      "Epoch 161/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2586 - acc: 0.9067\n",
      "Epoch 162/400\n",
      "45324/45324 [==============================] - 3s 66us/step - loss: 0.2566 - acc: 0.9060\n",
      "Epoch 163/400\n",
      "45324/45324 [==============================] - 3s 62us/step - loss: 0.2547 - acc: 0.9076\n",
      "Epoch 164/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2580 - acc: 0.9055\n",
      "Epoch 165/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2571 - acc: 0.9072\n",
      "Epoch 166/400\n",
      "45324/45324 [==============================] - 3s 62us/step - loss: 0.2570 - acc: 0.9077\n",
      "Epoch 167/400\n",
      "45324/45324 [==============================] - 3s 62us/step - loss: 0.2578 - acc: 0.9055\n",
      "Epoch 168/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2550 - acc: 0.9089\n",
      "Epoch 169/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2555 - acc: 0.9081\n",
      "Epoch 170/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2576 - acc: 0.9066\n",
      "Epoch 171/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2550 - acc: 0.9075\n",
      "Epoch 172/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2515 - acc: 0.9089\n",
      "Epoch 173/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2571 - acc: 0.9066\n",
      "Epoch 174/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2497 - acc: 0.9106\n",
      "Epoch 175/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2539 - acc: 0.9088\n",
      "Epoch 176/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2527 - acc: 0.9082\n",
      "Epoch 177/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2513 - acc: 0.9096\n",
      "Epoch 178/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2528 - acc: 0.9069\n",
      "Epoch 179/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2509 - acc: 0.9093\n",
      "Epoch 180/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2533 - acc: 0.9076\n",
      "Epoch 181/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2531 - acc: 0.9079\n",
      "Epoch 182/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2504 - acc: 0.9095\n",
      "Epoch 183/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2515 - acc: 0.9088\n",
      "Epoch 184/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2506 - acc: 0.9105\n",
      "Epoch 185/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2509 - acc: 0.9094\n",
      "Epoch 186/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2511 - acc: 0.9084\n",
      "Epoch 187/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2487 - acc: 0.9082\n",
      "Epoch 188/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2495 - acc: 0.9089\n",
      "Epoch 189/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2446 - acc: 0.9112\n",
      "Epoch 190/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2491 - acc: 0.9111\n",
      "Epoch 191/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2496 - acc: 0.9106\n",
      "Epoch 192/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2511 - acc: 0.9088\n",
      "Epoch 193/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2470 - acc: 0.9105\n",
      "Epoch 194/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2436 - acc: 0.9119\n",
      "Epoch 195/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2461 - acc: 0.9114\n",
      "Epoch 196/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2477 - acc: 0.9101\n",
      "Epoch 197/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2477 - acc: 0.9091\n",
      "Epoch 198/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2458 - acc: 0.9110\n",
      "Epoch 199/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2462 - acc: 0.9103\n",
      "Epoch 200/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2441 - acc: 0.9107: 1s - lo\n",
      "Epoch 201/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2440 - acc: 0.9113\n",
      "Epoch 202/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2453 - acc: 0.9108\n",
      "Epoch 203/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2402 - acc: 0.9121\n",
      "Epoch 204/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2421 - acc: 0.9131\n",
      "Epoch 205/400\n",
      "45324/45324 [==============================] - ETA: 0s - loss: 0.2422 - acc: 0.912 - 3s 58us/step - loss: 0.2422 - acc: 0.9125\n",
      "Epoch 206/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2432 - acc: 0.9112\n",
      "Epoch 207/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2439 - acc: 0.9123\n",
      "Epoch 208/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2400 - acc: 0.9129\n",
      "Epoch 209/400\n",
      "45324/45324 [==============================] - 3s 64us/step - loss: 0.2390 - acc: 0.9142\n",
      "Epoch 210/400\n",
      "45324/45324 [==============================] - 3s 70us/step - loss: 0.2428 - acc: 0.9113\n",
      "Epoch 211/400\n",
      "45324/45324 [==============================] - 3s 64us/step - loss: 0.2408 - acc: 0.9130\n",
      "Epoch 212/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2438 - acc: 0.9118\n",
      "Epoch 213/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2426 - acc: 0.9130\n",
      "Epoch 214/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2425 - acc: 0.9114\n",
      "Epoch 215/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2422 - acc: 0.9124\n",
      "Epoch 216/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2415 - acc: 0.9117\n",
      "Epoch 217/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2427 - acc: 0.9123\n",
      "Epoch 218/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2409 - acc: 0.9126\n",
      "Epoch 219/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2389 - acc: 0.9129\n",
      "Epoch 220/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2373 - acc: 0.9137\n",
      "Epoch 221/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2383 - acc: 0.9139\n",
      "Epoch 222/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2405 - acc: 0.9129\n",
      "Epoch 223/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2381 - acc: 0.9130\n",
      "Epoch 224/400\n",
      "45324/45324 [==============================] - 3s 63us/step - loss: 0.2367 - acc: 0.9146\n",
      "Epoch 225/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2376 - acc: 0.9126\n",
      "Epoch 226/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2410 - acc: 0.9132\n",
      "Epoch 227/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2398 - acc: 0.9126\n",
      "Epoch 228/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2361 - acc: 0.9146\n",
      "Epoch 229/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2364 - acc: 0.9155\n",
      "Epoch 230/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2400 - acc: 0.9123\n",
      "Epoch 231/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2369 - acc: 0.9138\n",
      "Epoch 232/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2353 - acc: 0.9140\n",
      "Epoch 233/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2382 - acc: 0.9136\n",
      "Epoch 234/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2362 - acc: 0.9143\n",
      "Epoch 235/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2356 - acc: 0.9152\n",
      "Epoch 236/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2360 - acc: 0.9136\n",
      "Epoch 237/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2367 - acc: 0.9146\n",
      "Epoch 238/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2361 - acc: 0.9145\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2370 - acc: 0.9140\n",
      "Epoch 240/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2366 - acc: 0.9140\n",
      "Epoch 241/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2336 - acc: 0.9168\n",
      "Epoch 242/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2335 - acc: 0.9150\n",
      "Epoch 243/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2320 - acc: 0.9169\n",
      "Epoch 244/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2326 - acc: 0.9164\n",
      "Epoch 245/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2341 - acc: 0.9150\n",
      "Epoch 246/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2333 - acc: 0.9158\n",
      "Epoch 247/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2339 - acc: 0.9152\n",
      "Epoch 248/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2323 - acc: 0.9167\n",
      "Epoch 249/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2316 - acc: 0.9166\n",
      "Epoch 250/400\n",
      "45324/45324 [==============================] - 3s 63us/step - loss: 0.2357 - acc: 0.9134\n",
      "Epoch 251/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.2330 - acc: 0.9147\n",
      "Epoch 252/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2319 - acc: 0.9160\n",
      "Epoch 253/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2322 - acc: 0.9160\n",
      "Epoch 254/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2337 - acc: 0.9153\n",
      "Epoch 255/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2322 - acc: 0.9137\n",
      "Epoch 256/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2266 - acc: 0.9181\n",
      "Epoch 257/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2320 - acc: 0.9148\n",
      "Epoch 258/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2298 - acc: 0.9168\n",
      "Epoch 259/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2295 - acc: 0.9156\n",
      "Epoch 260/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2319 - acc: 0.9175\n",
      "Epoch 261/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2298 - acc: 0.9159\n",
      "Epoch 262/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2328 - acc: 0.9155\n",
      "Epoch 263/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2311 - acc: 0.9176\n",
      "Epoch 264/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2298 - acc: 0.9178\n",
      "Epoch 265/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2273 - acc: 0.9172\n",
      "Epoch 266/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2289 - acc: 0.9163\n",
      "Epoch 267/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2307 - acc: 0.9149\n",
      "Epoch 268/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2287 - acc: 0.9174\n",
      "Epoch 269/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2269 - acc: 0.9187\n",
      "Epoch 270/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2272 - acc: 0.9175\n",
      "Epoch 271/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2262 - acc: 0.9174\n",
      "Epoch 272/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2290 - acc: 0.9166\n",
      "Epoch 273/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2252 - acc: 0.9175\n",
      "Epoch 274/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2253 - acc: 0.9185\n",
      "Epoch 275/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2268 - acc: 0.9170\n",
      "Epoch 276/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2281 - acc: 0.9162\n",
      "Epoch 277/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2288 - acc: 0.9172\n",
      "Epoch 278/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2261 - acc: 0.9182\n",
      "Epoch 279/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2287 - acc: 0.9169\n",
      "Epoch 280/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2275 - acc: 0.9183\n",
      "Epoch 281/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2254 - acc: 0.9184\n",
      "Epoch 282/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2266 - acc: 0.9180\n",
      "Epoch 283/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2281 - acc: 0.9174\n",
      "Epoch 284/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2234 - acc: 0.9192\n",
      "Epoch 285/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2231 - acc: 0.9198\n",
      "Epoch 286/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2234 - acc: 0.9193\n",
      "Epoch 287/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2270 - acc: 0.9181\n",
      "Epoch 288/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2271 - acc: 0.9163\n",
      "Epoch 289/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2257 - acc: 0.9186\n",
      "Epoch 290/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2259 - acc: 0.9192\n",
      "Epoch 291/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2229 - acc: 0.9179\n",
      "Epoch 292/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2247 - acc: 0.9182\n",
      "Epoch 293/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2252 - acc: 0.9180\n",
      "Epoch 294/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2208 - acc: 0.9197\n",
      "Epoch 295/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2269 - acc: 0.9176\n",
      "Epoch 296/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2220 - acc: 0.9196\n",
      "Epoch 297/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2241 - acc: 0.9183\n",
      "Epoch 298/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2249 - acc: 0.9188\n",
      "Epoch 299/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2212 - acc: 0.9182\n",
      "Epoch 300/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2218 - acc: 0.9189\n",
      "Epoch 301/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2196 - acc: 0.9203\n",
      "Epoch 302/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2230 - acc: 0.9181\n",
      "Epoch 303/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2218 - acc: 0.9180\n",
      "Epoch 304/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2233 - acc: 0.9190\n",
      "Epoch 305/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2213 - acc: 0.9197\n",
      "Epoch 306/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2195 - acc: 0.9199\n",
      "Epoch 307/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2219 - acc: 0.9181\n",
      "Epoch 308/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2197 - acc: 0.9209\n",
      "Epoch 309/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2200 - acc: 0.9208\n",
      "Epoch 310/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2202 - acc: 0.9200\n",
      "Epoch 311/400\n",
      "45324/45324 [==============================] - 3s 59us/step - loss: 0.2201 - acc: 0.9207\n",
      "Epoch 312/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2232 - acc: 0.9195\n",
      "Epoch 313/400\n",
      "45324/45324 [==============================] - 3s 61us/step - loss: 0.2173 - acc: 0.9211\n",
      "Epoch 314/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2188 - acc: 0.9192\n",
      "Epoch 315/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2196 - acc: 0.9207\n",
      "Epoch 316/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2171 - acc: 0.9204\n",
      "Epoch 317/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2209 - acc: 0.9198\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2192 - acc: 0.9202\n",
      "Epoch 319/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2201 - acc: 0.9190\n",
      "Epoch 320/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2188 - acc: 0.9207\n",
      "Epoch 321/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2193 - acc: 0.9197\n",
      "Epoch 322/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2166 - acc: 0.9204\n",
      "Epoch 323/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2187 - acc: 0.9215\n",
      "Epoch 324/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2182 - acc: 0.9207\n",
      "Epoch 325/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2174 - acc: 0.9209\n",
      "Epoch 326/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2154 - acc: 0.9214\n",
      "Epoch 327/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2189 - acc: 0.9211\n",
      "Epoch 328/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2192 - acc: 0.9197\n",
      "Epoch 329/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2168 - acc: 0.9218: 0s - loss: 0.2169 -\n",
      "Epoch 330/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2198 - acc: 0.9201\n",
      "Epoch 331/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2184 - acc: 0.9212\n",
      "Epoch 332/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2152 - acc: 0.9226\n",
      "Epoch 333/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2164 - acc: 0.9216\n",
      "Epoch 334/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2154 - acc: 0.9223\n",
      "Epoch 335/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2192 - acc: 0.9201\n",
      "Epoch 336/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2163 - acc: 0.9214\n",
      "Epoch 337/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2150 - acc: 0.9213\n",
      "Epoch 338/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2169 - acc: 0.9215\n",
      "Epoch 339/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2167 - acc: 0.9212\n",
      "Epoch 340/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2182 - acc: 0.9207\n",
      "Epoch 341/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2158 - acc: 0.9204\n",
      "Epoch 342/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2156 - acc: 0.9209\n",
      "Epoch 343/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2163 - acc: 0.9214\n",
      "Epoch 344/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2149 - acc: 0.9226\n",
      "Epoch 345/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2141 - acc: 0.9217\n",
      "Epoch 346/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2136 - acc: 0.9214\n",
      "Epoch 347/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2152 - acc: 0.9220\n",
      "Epoch 348/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2126 - acc: 0.9228\n",
      "Epoch 349/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2173 - acc: 0.9209\n",
      "Epoch 350/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2132 - acc: 0.9225\n",
      "Epoch 351/400\n",
      "45324/45324 [==============================] - 2s 48us/step - loss: 0.2158 - acc: 0.9202\n",
      "Epoch 352/400\n",
      "45324/45324 [==============================] - 2s 49us/step - loss: 0.2170 - acc: 0.9203\n",
      "Epoch 353/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2138 - acc: 0.9224\n",
      "Epoch 354/400\n",
      "45324/45324 [==============================] - 2s 48us/step - loss: 0.2133 - acc: 0.9222\n",
      "Epoch 355/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2118 - acc: 0.9217\n",
      "Epoch 356/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2145 - acc: 0.9220\n",
      "Epoch 357/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2141 - acc: 0.9218\n",
      "Epoch 358/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2145 - acc: 0.9218\n",
      "Epoch 359/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2095 - acc: 0.9242\n",
      "Epoch 360/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2125 - acc: 0.9230\n",
      "Epoch 361/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2129 - acc: 0.9220\n",
      "Epoch 362/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2167 - acc: 0.9207\n",
      "Epoch 363/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2113 - acc: 0.9238\n",
      "Epoch 364/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2137 - acc: 0.9218\n",
      "Epoch 365/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2101 - acc: 0.9237\n",
      "Epoch 366/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2113 - acc: 0.9225\n",
      "Epoch 367/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2137 - acc: 0.9220\n",
      "Epoch 368/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2108 - acc: 0.9235\n",
      "Epoch 369/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2096 - acc: 0.9234\n",
      "Epoch 370/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2118 - acc: 0.9234\n",
      "Epoch 371/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2124 - acc: 0.9224\n",
      "Epoch 372/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2106 - acc: 0.9218\n",
      "Epoch 373/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2119 - acc: 0.9234\n",
      "Epoch 374/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2098 - acc: 0.9243\n",
      "Epoch 375/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2106 - acc: 0.9229\n",
      "Epoch 376/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2118 - acc: 0.9226\n",
      "Epoch 377/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2128 - acc: 0.9224\n",
      "Epoch 378/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2107 - acc: 0.9239\n",
      "Epoch 379/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2100 - acc: 0.9233\n",
      "Epoch 380/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2102 - acc: 0.9229\n",
      "Epoch 381/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2125 - acc: 0.9227\n",
      "Epoch 382/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2118 - acc: 0.9226\n",
      "Epoch 383/400\n",
      "45324/45324 [==============================] - 3s 60us/step - loss: 0.2102 - acc: 0.9237\n",
      "Epoch 384/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2090 - acc: 0.9243\n",
      "Epoch 385/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2085 - acc: 0.9245: 0s - loss: 0.20\n",
      "Epoch 386/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2109 - acc: 0.9238\n",
      "Epoch 387/400\n",
      "45324/45324 [==============================] - 2s 50us/step - loss: 0.2077 - acc: 0.9256\n",
      "Epoch 388/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2122 - acc: 0.9214\n",
      "Epoch 389/400\n",
      "45324/45324 [==============================] - 3s 55us/step - loss: 0.2075 - acc: 0.9241\n",
      "Epoch 390/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2120 - acc: 0.9222\n",
      "Epoch 391/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2076 - acc: 0.9241\n",
      "Epoch 392/400\n",
      "45324/45324 [==============================] - 3s 57us/step - loss: 0.2126 - acc: 0.9213\n",
      "Epoch 393/400\n",
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2091 - acc: 0.9234\n",
      "Epoch 394/400\n",
      "45324/45324 [==============================] - 3s 56us/step - loss: 0.2068 - acc: 0.9243\n",
      "Epoch 395/400\n",
      "45324/45324 [==============================] - 2s 55us/step - loss: 0.2108 - acc: 0.9221\n",
      "Epoch 396/400\n",
      "45324/45324 [==============================] - 3s 58us/step - loss: 0.2068 - acc: 0.9245\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45324/45324 [==============================] - 2s 53us/step - loss: 0.2069 - acc: 0.9239\n",
      "Epoch 398/400\n",
      "45324/45324 [==============================] - 2s 52us/step - loss: 0.2068 - acc: 0.9253\n",
      "Epoch 399/400\n",
      "45324/45324 [==============================] - 2s 54us/step - loss: 0.2088 - acc: 0.9228\n",
      "Epoch 400/400\n",
      "45324/45324 [==============================] - 2s 51us/step - loss: 0.2085 - acc: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd1d369358>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#Easy way to convert to one-hot\n",
    "y_train_hot2 = keras.utils.to_categorical(y_train, num_classes=5)\n",
    "\n",
    "model.fit(x_train, y_train_hot2, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_one_hot = model.predict(x_test)\n",
    "type(pred_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert predictions back from 1-hot\n",
    "pred = []\n",
    "\n",
    "for line in pred_one_hot:\n",
    "    pred.append(np.argmax(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Id': test.index, 'y': pred}\n",
    "out = pd.DataFrame(d)\n",
    "out.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
